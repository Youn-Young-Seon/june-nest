---
description: 
globs: 
alwaysApply: true
---
# FxTS Functional Programming Guidelines

## Overview
This project uses [FxTS](mdc:https:/fxts.dev/docs) for functional programming patterns in TypeScript/JavaScript. FxTS provides two main categories of functions: **Lazy** (for lazy evaluation and iterators) and **Strict** (for strict evaluation on arrays and objects).

## 🚨 CRITICAL: Understanding Lazy Evaluation and Iterator Protocol

### ⚠️ Key Concept: Iterator vs Array Returns
**FxTS functions return Iterators, NOT arrays.** This is crucial for avoiding type errors.

```typescript
// ❌ WRONG: Assuming map returns an array
const result = pipe(
  users,
  map(user => ({ ...user, processed: true })),
  // This is an Iterator, not an array!
);

// ✅ CORRECT: Understanding Iterator flow
const result = pipe(
  users,
  map(user => ({ ...user, processed: true })),
  toArray  // Converts Iterator to Array (may return Promise<T[]>!)
);
```

### 🔑 When toArray Returns Promise<T[]>
The `toArray` function can return either `T[]` or `Promise<T[]>` depending on pipeline complexity:

```typescript
// Simple case - returns T[]
const result = pipe([1, 2, 3], map(x => x * 2), toArray);

// Complex case - returns Promise<T[]>  
const result = pipe(
  largeDataset,
  filter(item => expensiveCheck(item)),
  map(item => transform(item)),
  toArray  // ⚠️ This may return Promise<T[]>!
);
```

## Function Categories

### Lazy Functions
Use lazy functions for:
- Large datasets that don't need to be fully processed
- Chaining operations that may not need all results
- Memory-efficient data processing
- Infinite or very large sequences

Common lazy functions:
- `map`, `filter`, `take`, `drop`, `chunk`, `flatten`, `uniq`
- `range`, `repeat`, `cycle` for sequence generation
- `concurrent`, `concurrentPool` for async operations

### Strict Functions
Use strict functions for:
- Small to medium datasets
- Operations that need immediate results
- Final transformations in a pipeline
- Simple data queries

Common strict functions:
- `reduce`, `find`, `some`, `every`, `includes`
- `groupBy`, `countBy`, `partition`, `sortBy`
- `pick`, `omit`, `prop`, `props` for object manipulation

## 🚀 ESSENTIAL: Asynchronous Pipeline Best Practices

### 💡 Rule #1: Use toAsync for Complex Pipelines
When working with complex transformations or when `toArray` returns a Promise, **always use `toAsync`**:

```typescript
// ✅ BEST PRACTICE: Explicit async pipeline
const processedUsers = await pipe(
  users,
  toAsync,  // 🔑 KEY: Convert to AsyncIterable
  filter(user => user.isActive),
  map(user => ({
    ...user,
    displayName: user.name || user.email,
    videoCount: user.Video.length
  })),
  sortBy(user => user.createdAt),
  take(10),
  toArray   // Now safely returns Promise<T[]>
);
```

### 💡 Rule #2: Always Await Async Pipelines
When using `toAsync` or when pipeline returns Promise, **always use `await`**:

```typescript
// ❌ WRONG: Not awaiting Promise
const result = pipe(
  data,
  toAsync,
  map(item => process(item)),
  toArray,
  items => items.filter(...)  // ERROR: items is Promise, not array
);

// ✅ CORRECT: Proper await handling
const processedItems = await pipe(
  data,
  toAsync,
  map(item => process(item)),
  toArray
);
const result = processedItems.filter(...);  // Now items is actual array
```

### 💡 Rule #3: Separate Transformation and Post-Processing
For better type safety and readability:

```typescript
// ✅ BEST PRACTICE: Clear separation
const transformedData = await pipe(
  rawData,
  toAsync,
  filter(isValid),
  map(transform),
  sortBy(item => item.priority),
  toArray
);

// Now use regular array methods safely
const finalResult = transformedData
  .slice(0, 10)
  .map(item => ({ ...item, processed: true }));
```

## Pipeline Composition

### Preferred Pattern: Use `pipe` for Data Transformation
```typescript
// ✅ GOOD: Clear data transformation pipeline
const processUsers = (users: User[]) =>
  pipe(
    users,
    filter(user => user.isActive),
    map(user => ({ ...user, displayName: `${user.firstName} ${user.lastName}` })),
    sortBy(user => user.createdAt),
    take(10)
  );
```

### Use `pipeLazy` for Lazy Evaluation
```typescript
// ✅ GOOD: Lazy pipeline for large datasets
const processLargeDataset = (data: Iterable<Item>) =>
  pipeLazy(
    data,
    filter(item => item.isValid),
    map(item => transform(item)),
    chunk(100),
    take(5) // Only process first 5 chunks
  );
```

### Avoid Nested Function Calls
```typescript
// ❌ BAD: Hard to read nested calls
const result = take(10, 
  sortBy(user => user.createdAt,
    map(user => ({ ...user, displayName: `${user.firstName} ${user.lastName}` }),
      filter(user => user.isActive, users)
    )
  )
);

// ✅ GOOD: Use pipe for readability
const result = pipe(
  users,
  filter(user => user.isActive),
  map(user => ({ ...user, displayName: `${user.firstName} ${user.lastName}` })),
  sortBy(user => user.createdAt),
  take(10)
);
```

## Data Transformation Best Practices

### Object Manipulation
```typescript
// ✅ GOOD: Use FxTS object utilities
const userSummary = pipe(
  user,
  pick(['id', 'name', 'email']),
  evolve({
    name: name => name.toUpperCase(),
    email: email => email.toLowerCase()
  })
);

// ✅ GOOD: Safe property access
const userName = prop('name', user);
const userProps = props(['name', 'email'], user);
```

### Array Processing
```typescript
// ✅ GOOD: Use appropriate functions for array operations
const activeUsers = pipe(
  users,
  filter(user => user.isActive),
  uniqBy(user => user.email), // Remove duplicates by email
  sortBy(user => user.lastName)
);

// ✅ GOOD: Use reduce for aggregations
const userStats = pipe(
  users,
  reduce((acc, user) => ({
    total: acc.total + 1,
    active: acc.active + (user.isActive ? 1 : 0)
  }), { total: 0, active: 0 })
);
```

### Conditional Logic
```typescript
// ✅ GOOD: Use functional conditional utilities
const processUser = (user: User) => pipe(
  user,
  when(user => user.isNewUser, evolve({ status: () => 'pending' })),
  unless(user => user.isVerified, omit(['sensitiveData']))
);
```

## Performance Considerations

### When to Use toAsync
Use `toAsync` in these critical scenarios:

1. **Complex transformations** that might involve async operations
2. **Large datasets** where lazy evaluation is beneficial  
3. **When toArray returns Promise** (detected through type errors)
4. **Service layer methods** for consistent async handling

```typescript
// ✅ GOOD: Complex transformation pipeline
const analytics = await pipe(
  users,
  toAsync,  // Handle complex processing
  filter(user => user.isActive),
  map(async user => ({
    ...user,
    stats: await calculateUserStats(user)  // Async operation
  })),
  sortBy(user => user.stats.score),
  take(100),
  toArray
);
```

### Memory Efficiency with Lazy Evaluation
```typescript
// ✅ GOOD: Memory-efficient processing
const topUsers = await pipe(
  millionsOfUsers,
  toAsync,
  filter(user => user.isActive),
  sortBy(user => user.score),
  take(10),  // Only process top 10, not all millions
  toArray
);
```

### Lazy vs Strict Choice
```typescript
// ✅ GOOD: Use lazy for large datasets or partial processing
const firstActiveUser = pipe(
  users, // Large array
  filter(user => user.isActive), // Lazy - stops when first match found
  take(1), // Only need first result
  toArray // Convert to array at the end
);

// ✅ GOOD: Use strict for small datasets or complete processing
const userCount = pipe(
  users, // Small array, need all results
  filter(user => user.isActive),
  size // Need complete count
);
```

### Concurrent Processing
```typescript
// ✅ GOOD: Use concurrent for async operations
const enrichedUsers = await pipe(
  users,
  toAsync,  // Always use toAsync with concurrent
  concurrent(async user => ({
    ...user,
    profile: await fetchUserProfile(user.id)
  })),
  toArray
);

// ✅ GOOD: Use concurrentPool for rate limiting
const processedUsers = await pipe(
  users,
  toAsync,  // Always use toAsync with concurrentPool
  concurrentPool(5, async user => await processUser(user)), // Max 5 concurrent
  toArray
);
```

## Type Safety Guidelines

### Generic Functions
```typescript
// ✅ GOOD: Explicit type annotations for complex transformations
const transformUsers = <T extends User>(users: T[]): UserSummary[] =>
  pipe(
    users,
    map((user: T): UserSummary => ({
      id: user.id,
      name: user.name,
      isActive: user.isActive
    }))
  );
```

### Utility Functions
```typescript
// ✅ GOOD: Use FxTS type guards
const validateUser = (user: unknown): user is User => 
  isObject(user) && 
  isString(prop('name', user)) && 
  isBoolean(prop('isActive', user));

// ✅ GOOD: Use isEmpty for null/undefined checks
const hasValidEmail = (user: User): boolean => 
  !isEmpty(user.email) && isString(user.email);
```

## Common Patterns

### Data Aggregation
```typescript
// ✅ GOOD: Group and aggregate data
const usersByDepartment = pipe(
  users,
  groupBy(user => user.department),
  map(users => ({
    count: size(users),
    activeCount: pipe(users, filter(user => user.isActive), size)
  }))
);
```

### Error Handling
```typescript
// ✅ GOOD: Use throwIf for validation
const validateAndProcess = (data: unknown) => pipe(
  data,
  throwIf(isEmpty, 'Data cannot be empty'),
  throwIf(data => !isArray(data), 'Data must be an array'),
  map(processItem)
);
```

### Memoization
```typescript
// ✅ GOOD: Use memoize for expensive computations
const expensiveComputation = memoize((input: string) => {
  // Expensive operation
  return computeResult(input);
});
```

## 🚨 Critical Anti-Patterns to Avoid

### ❌ Anti-Pattern #1: Ignoring Promise Returns
```typescript
// ❌ BAD: Ignoring that toArray might return Promise
const result = pipe(data, map(...), toArray);
return result.length;  // ERROR if result is Promise

// ✅ GOOD: Handling Promise correctly
const result = await pipe(data, toAsync, map(...), toArray);
return result.length;
```

### ❌ Anti-Pattern #2: Mixing Sync/Async Inconsistently
```typescript
// ❌ BAD: Inconsistent async handling
const part1 = pipe(data, map(...), toArray);  // Might be Promise
const part2 = data.filter(...);  // Always array
return [...part1, ...part2];  // ERROR if part1 is Promise

// ✅ GOOD: Consistent async handling
const part1 = await pipe(data, toAsync, map(...), toArray);
const part2 = data.filter(...);
return [...part1, ...part2];
```

### ❌ Anti-Pattern #3: Not Using toAsync When Needed
```typescript
// ❌ BAD: Complex pipeline without toAsync
const result = pipe(
  complexData,
  filter(expensiveCheck),
  map(heavyTransform),
  toArray,
  items => items.slice(0, 10)  // ERROR: items might be Promise
);

// ✅ GOOD: Explicit async handling
const items = await pipe(
  complexData,
  toAsync,
  filter(expensiveCheck),
  map(heavyTransform),
  toArray
);
const result = items.slice(0, 10);
```

### ❌ Anti-Pattern #4: Mixing Paradigms
```typescript
// ❌ BAD: Mixing imperative and functional styles
const processUsers = (users: User[]) => {
  const filtered = filter(user => user.isActive, users);
  const result = [];
  for (const user of filtered) {
    result.push({ ...user, processed: true });
  }
  return result;
};

// ✅ GOOD: Pure functional approach
const processUsers = async (users: User[]) => await pipe(
  users,
  toAsync,
  filter(user => user.isActive),
  map(user => ({ ...user, processed: true })),
  toArray
);
```

### ❌ Anti-Pattern #5: Ignoring Lazy Evaluation Benefits
```typescript
// ❌ BAD: Converting to array too early
const result = pipe(
  largeDataset,
  toArray, // Loses lazy evaluation benefits
  filter(item => item.isValid),
  take(10)
);

// ✅ GOOD: Keep lazy until the end
const result = await pipe(
  largeDataset,
  toAsync,
  filter(item => item.isValid),
  take(10),
  toArray // Convert only when needed
);
```

## Integration with NestJS

### Service Layer Best Practices
```typescript
// ✅ EXCELLENT: Proper async FxTS in service
@Injectable()
export class UserService {
  async getActiveUsers(): Promise<UserSummary[]> {
    const users = await this.prisma.user.findMany({ ... });
    
    return await pipe(
      users,
      toAsync,  // 🔑 Always use toAsync for service methods
      filter(user => user.isActive),
      map(user => this.toUserSummary(user)),
      sortBy(user => user.createdAt),
      take(10),
      toArray
    );
  }
  
  async getUserAnalytics(): Promise<UserAnalytics> {
    const users = await this.prisma.user.findMany({ ... });
    
    const [activeUsers, usersByRole, topUploaders] = await Promise.all([
      pipe(
        users,
        toAsync,
        filter(user => user.isActive),
        toArray
      ),
      pipe(
        users,
        toAsync,
        groupBy(user => user.role),
        toArray
      ),
      pipe(
        users,
        toAsync,
        sortBy(user => user.Video.length),
        take(5),
        toArray
      )
    ]);
    
    return { activeUsers, usersByRole, topUploaders };
  }
}
```

### Controller Layer
```typescript
// ✅ GOOD: Transform data in controllers
@Controller('users')
export class UserController {
  @Get()
  async getUsers(@Query() query: GetUsersQuery) {
    const users = await this.userService.findUsers(query);
    
    return await pipe(
      users,
      toAsync,  // Use toAsync in controllers too
      map(user => omit(['password', 'internalId'], user)),
      when(() => query.includeInactive, identity),
      unless(() => query.includeInactive, filter(user => user.isActive)),
      toArray
    );
  }
}
```

### Error Handling in Services
```typescript
@Injectable()
export class DataService {
  async processData(data: DataInput[]): Promise<ProcessedData[]> {
    try {
      return await pipe(
        data,
        toAsync,
        filter(this.isValid),
        map(async item => await this.transform(item)),
        toArray
      );
    } catch (error) {
      this.logger.error('FxTS pipeline failed:', error);
      throw new InternalServerErrorException('Data processing failed');
    }
  }
}

## Testing with FxTS

### Unit Tests for Async Pipelines
```typescript
// ✅ EXCELLENT: Test async FxTS pipelines
describe('UserService', () => {
  it('should process users correctly', async () => {
    const users = [
      { id: 1, name: 'John', isActive: true },
      { id: 2, name: 'Jane', isActive: false }
    ];
    
    const result = await pipe(
      users,
      toAsync,  // Use toAsync in tests too
      filter(user => user.isActive),
      map(user => user.name),
      toArray
    );
    
    expect(result).toEqual(['John']);
  });
  
  it('should handle empty input', async () => {
    const result = await pipe(
      [],
      toAsync,
      map(x => x * 2),
      toArray
    );
    
    expect(result).toEqual([]);
  });
  
  it('should handle errors properly', async () => {
    const users = [{ id: 1, name: 'John' }];
    
    await expect(
      pipe(
        users,
        toAsync,
        map(user => { throw new Error('Test error'); }),
        toArray
      )
    ).rejects.toThrow('Test error');
  });
});
```

### Integration Tests
```typescript
// ✅ GOOD: Test service integration
describe('UserService Integration', () => {
  it('should get analytics correctly', async () => {
    const service = new UserService(mockPrisma);
    
    const analytics = await service.getUserAnalytics();
    
    expect(analytics.activeUsers).toBeDefined();
    expect(analytics.usersByRole).toBeDefined();
    expect(analytics.topUploaders).toBeDefined();
  });
});
```

## 📋 Quick Reference Summary

### 🔑 Key Rules to Remember:
1. **Always use `toAsync`** for complex pipelines and service methods
2. **Always `await`** when using `toAsync` or when `toArray` might return Promise
3. **Separate FxTS transformations** from regular array operations
4. **Handle type errors** by understanding Iterator vs Array returns
5. **Use lazy evaluation** for memory efficiency with large datasets
6. **Test async pipelines** properly with await in tests
7. **Add proper error handling** around complex FxTS operations

### 🚨 Critical Pattern:
```typescript
// ✅ THE GOLDEN PATTERN for NestJS Services
const result = await pipe(
  data,
  toAsync,  // Always start with toAsync
  filter(...),
  map(...),
  sortBy(...),
  take(...),
  toArray   // Always end with toArray
);
```

Remember: FxTS promotes immutability, composability, and clear data transformation pipelines. Always prefer functional approaches over imperative ones when working with data transformations.



